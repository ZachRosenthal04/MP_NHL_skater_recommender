{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder, MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "\n",
    "# Load the datasets\n",
    "pd.set_option('display.max_columns', None) # Display Preference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_AS = pd.read_csv('MP_AS_stats_bios_new_features.csv')\n",
    "mod_5on5 = pd.read_csv('MP_5on5_stats_bios_new_features.csv')\n",
    "mod_4on5 = pd.read_csv('MP_4on5_stats_bios_new_features.csv')\n",
    "mod_5on4 = pd.read_csv('MP_5on4_stats_bios_new_features.csv')\n",
    "mod_OS = pd.read_csv('MP_OS_stats_bios_new_features.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Regressor:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using the random forest regressor to see how accurately my model can predict the gameScore for future seasons \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column transformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), make_column_selector(dtype_include=['int64', 'float64'])),\n",
    "        ('age_group', Pipeline([\n",
    "            ('ordinal', OrdinalEncoder(categories=[['New Pro', 'Young Pro', 'Prime Age', 'Vet', 'Old Vet']])),\n",
    "            ('scaler', StandardScaler())  # Scale the ordinal-encoded age_group\n",
    "        ]), ['age_group']),\n",
    "        ('position', Pipeline([\n",
    "            ('onehot', OneHotEncoder()),  # Apply OneHotEncoder to 'position'\n",
    "            ('scaler', StandardScaler(with_mean=False))  # Apply StandardScaler after OneHotEncoder\n",
    "        ]), ['position'])\n",
    "    ])\n",
    "\n",
    "# My current Pipeline\n",
    "MP_RFR_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', RandomForestRegressor(n_estimators=100, random_state=42))  # Random Forest Regressor\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_not_processed = ['playerId', 'season' , 'name', 'team', 'situation', 'iceTimeRank', 'I_F_shifts',\n",
    "                      'nationality' ,'birthDate', 'weight','height', 'shoots', 'age' ,'gameScore', 'ZR_gameScore', 'playerRating', 'ZR_playerRating'] \n",
    "# gameScore is the target variable\n",
    "\n",
    "col_not_processed_without_points = ['playerId', 'season' , 'name', 'team', 'situation', 'iceTimeRank', 'I_F_shifts',\n",
    "                      'nationality' ,'birthDate', 'weight','height', 'shoots', 'age' , 'I_F_points','gameScore', 'ZR_gameScore', 'playerRating', 'ZR_playerRating'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I_F_points                                    0.904845\n",
      "onIce_fenwickPercentage                       0.013960\n",
      "onIce_corsiPercentage                         0.009082\n",
      "OnIce_F_scoreAdjustedUnblockedShotAttempts    0.004477\n",
      "I_F_scoreAdjustedShotsAttempts                0.003807\n",
      "offIce_xGoalsPercentage                       0.003801\n",
      "offIce_corsiPercentage                        0.003559\n",
      "offIce_fenwickPercentage                      0.003338\n",
      "onIce_xGoalsPercentage                        0.003032\n",
      "I_F_oZoneShiftEnds                            0.001937\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Drop the target column to create the feature matrix X\n",
    "MP_AS_X = mod_AS.drop(columns=col_not_processed) \n",
    "MP_AS_y = mod_AS['gameScore']  # Target variable\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "MP_AS_X_train, MP_AS_X_test, MP_AS_y_train, MP_AS_y_test = train_test_split(MP_AS_X, MP_AS_y, test_size=0.2, random_state=42)\n",
    "# Fit the pipeline to your training data\n",
    "AS_model = MP_RFR_pipeline.fit(MP_AS_X_train, MP_AS_y_train)\n",
    "\n",
    "# Access the trained Random Forest model inside the pipeline\n",
    "rf_model = AS_model.named_steps['regressor']\n",
    "\n",
    "# Access the preprocessor step to get the transformed feature names\n",
    "preprocessor = AS_model.named_steps['preprocessor']\n",
    "\n",
    "# Get feature names after the transformation\n",
    "def get_feature_names(column_transformer):\n",
    "    output_features = []\n",
    "    for name, transformer, features in column_transformer.transformers_:\n",
    "        if transformer == 'drop' or transformer is None:\n",
    "            continue\n",
    "        if isinstance(transformer, Pipeline):\n",
    "            transformer = transformer.named_steps['onehot'] if 'onehot' in transformer.named_steps else transformer\n",
    "        try:\n",
    "            if hasattr(transformer, 'get_feature_names_out'):\n",
    "                feature_names = transformer.get_feature_names_out(features)\n",
    "                output_features.extend(feature_names)\n",
    "            else:\n",
    "                output_features.extend(features)\n",
    "        except NotFittedError:\n",
    "            output_features.extend(features)\n",
    "    return output_features\n",
    "\n",
    "# Get the transformed feature names\n",
    "transformed_feature_names = get_feature_names(preprocessor)\n",
    "\n",
    "# Get feature importances from the Random Forest model\n",
    "feature_importances = pd.Series(rf_model.feature_importances_, index=transformed_feature_names)\n",
    "feature_importances.sort_values(ascending=False, inplace=True)\n",
    "\n",
    "# Display the most important features\n",
    "print(feature_importances.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AS Model -  Comparing the accuracy of the model with and without the I_F_points column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with I_F_points:\n",
      "Mean Squared Error: 16.62153429479167\n",
      "R2 Score: 0.9723422374579082\n",
      "Model without I_F_points:\n",
      "Mean Squared Error: 22.02977477850695\n",
      "R2 Score: 0.9633430783901441/n\n",
      "Comparison of Model Performance:\n",
      "Difference in MSE: 5.408240483715282\n",
      "Difference in R2 Score: -0.008999159067764051\n"
     ]
    }
   ],
   "source": [
    "# Re assign the variable so that the comparison doesn't throw an error\n",
    "MP_AS_X = mod_AS.drop(columns=col_not_processed) \n",
    "MP_AS_y = mod_AS['gameScore']  # Target variable\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "MP_AS_X_train, MP_AS_X_test, MP_AS_y_train, MP_AS_y_test = train_test_split(MP_AS_X, MP_AS_y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 1: Train and evaluate with I_F_points included\n",
    "# Assume your original training set includes I_F_points\n",
    "AS_model_with_points = MP_RFR_pipeline.fit(MP_AS_X_train, MP_AS_y_train)\n",
    "predictions_with_points = AS_model_with_points.predict(MP_AS_X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse_with_points = mean_squared_error(MP_AS_y_test, predictions_with_points)\n",
    "r2_with_points = r2_score(MP_AS_y_test, predictions_with_points)\n",
    "\n",
    "print(\"Model with I_F_points:\")\n",
    "print(f\"Mean Squared Error: {mse_with_points}\")\n",
    "print(f\"R2 Score: {r2_with_points}\")\n",
    "\n",
    "# Step 2: Train and evaluate with I_F_points removed\n",
    "# Remove the I_F_points column from your training and testing sets\n",
    "MP_AS_X_train_no_points = MP_AS_X_train.drop(columns=['I_F_points'])\n",
    "MP_AS_X_test_no_points = MP_AS_X_test.drop(columns=['I_F_points'])\n",
    "\n",
    "AS_model_without_points = MP_RFR_pipeline.fit(MP_AS_X_train_no_points, MP_AS_y_train)\n",
    "predictions_without_points = AS_model_without_points.predict(MP_AS_X_test_no_points)\n",
    "\n",
    "# Evaluate the model\n",
    "mse_without_points = mean_squared_error(MP_AS_y_test, predictions_without_points)\n",
    "r2_without_points = r2_score(MP_AS_y_test, predictions_without_points)\n",
    "\n",
    "print(\"Model without I_F_points:\")\n",
    "print(f\"Mean Squared Error: {mse_without_points}\")\n",
    "print(f\"R2 Score: {r2_without_points}/n\")\n",
    "\n",
    "# Step 3: Compare the two models\n",
    "print(\"Comparison of Model Performance:\")\n",
    "print(f\"Difference in MSE: {mse_without_points - mse_with_points}\")\n",
    "print(f\"Difference in R2 Score: {r2_without_points - r2_with_points}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring how to weight xGoals for each scoring chance category low, med, high:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24634.84\n",
      "7256.17\n",
      "8331.32\n",
      "9047.81\n",
      "the AS LDxG_percentage is:   29.454910200350398\n",
      "the AS MDxG_percentage is:   33.81925760427102\n",
      "the AS HDxG_percentage is:   36.727699469531764\n"
     ]
    }
   ],
   "source": [
    "AS_total_xGoals = mod_AS['I_F_xGoals'].sum()\n",
    "print(AS_total_xGoals)\n",
    "\n",
    "AS_total_lowDangerxGoals = mod_AS['I_F_lowDangerxGoals'].sum()\n",
    "print(AS_total_lowDangerxGoals)\n",
    "\n",
    "AS_total_medDangerxGoals = mod_AS['I_F_mediumDangerxGoals'].sum()\n",
    "print(AS_total_medDangerxGoals)\n",
    "\n",
    "AS_total_highDangerxGoals = mod_AS['I_F_highDangerxGoals'].sum()\n",
    "print(AS_total_highDangerxGoals)\n",
    "\n",
    "#find the scoring chance xGoals percentage for weighting.\n",
    "AS_LDxG_percent = 100 * (AS_total_lowDangerxGoals/AS_total_xGoals)\n",
    "print('the AS LDxG_percentage is:  ', AS_LDxG_percent)\n",
    "\n",
    "AS_MDxG_percent = 100 * (AS_total_medDangerxGoals/AS_total_xGoals)\n",
    "print('the AS MDxG_percentage is:  ', AS_MDxG_percent)\n",
    "\n",
    "AS_HDxG_percent = 100 * (AS_total_highDangerxGoals/AS_total_xGoals)\n",
    "print('the AS HDxG_percentage is:  ', AS_HDxG_percent)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "THE_ONE_env",
   "language": "python",
   "name": "the_one_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
